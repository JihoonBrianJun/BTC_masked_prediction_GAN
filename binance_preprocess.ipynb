{"cells":[{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[],"source":["# Set the data path, and get the list of files to be preprocessed\n","\n","trade_data_path = os.path.join(os.getcwd(),'daily_data','trade')\n","ohlcv_data_path = os.path.join(os.getcwd(),'daily_data','ohlcv')\n","preprocessed_data_path = os.path.join(os.getcwd(),'daily_data','preprocessed')\n","\n","trade_data_files = sorted(os.listdir(trade_data_path))\n","ohlcv_data_files = sorted(os.listdir(ohlcv_data_path))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Original csv files downloaded from https://www.binance.com/en/landing/data do not include column names\n","# Column names and descriptions can be found in https://www.binance.com/en/support/faq/how-to-download-historical-market-data-on-binance-5810ae42176b4770b880ce1f14932262\n","# Manually set the column names based on it\n","\n","trade_column_list = ['ID', 'price', 'qty', 'quote_qty', 'time', 'is_buyer_maker','is_best_match']\n","ohlcv_column_list = ['open_time','open','high','low','close','volume','close_time','quote_volume','num_trade','taker_buy_base','taker_buy_quote','ignore']"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 31/31 [00:27<00:00,  1.11it/s]\n"]}],"source":["for i in tqdm(range(len(trade_data_files))):\n","    # Load the raw trade data\n","    trade = pd.read_csv(os.path.join(trade_data_path,trade_data_files[i]), names = trade_column_list)\n","    ohlcv = pd.read_csv(os.path.join(ohlcv_data_path,ohlcv_data_files[i]), names = ohlcv_column_list)\n","    trade_date = trade_data_files[i][-14:-4]\n","    ohlcv_date = ohlcv_data_files[i][-14:-4]\n","    assert trade_date == ohlcv_date                                                     # check if the dates of two csv files are identical\n","    \n","    trade['is_price_up'] = trade['price'].gt(trade['price'].shift(1)).astype(float)     # 1 if price increased from the last tick data, otherwise 0\n","    trade['is_price_down'] = trade['price'].lt(trade['price'].shift(1)).astype(float)   # 1 if price decreased from the last tick data, otherwise 0\n","    trade['price_up_down'] = trade['is_price_up'] - trade['is_price_down']              # 1 if price increased, -1 if price decreased, 0 if price remained same\n","    \n","    # Define \"meaningful data\" to be the tick data such that\n","    # either price increased and buyer is the maker,\n","    # or price decreased and seller is the maker\n","    trade['is_meaningful'] = trade['price_up_down'] * (2*trade['is_buyer_maker']-1)     # 1 only if the tick data is meaningful\n","    trade = trade[trade['is_meaningful']==1].reset_index().drop('index',axis=1)         # Leave only meaningful data\n","    \n","    ohlcv['ud'] = ohlcv['close'] - ohlcv['open']                                        # difference between opening and close price for each minute\n","    ohlcv['ma'] = (ohlcv['close'].rolling(5).mean() - ohlcv['close'].rolling(20).mean()).shift(1)  # Previous difference between 5min moving average and 20min moving average\n","    \n","    # Match each timestamp of the trade data to the corresponding index of 1-minute interval within the day\n","    trade['time'] = (trade['time'] - ohlcv['open_time'].loc[0]) // 60000\n","    \n","    # Calculate the ratio of upward movement(increase in price from the last tick data) within the meaningful data of each minute interval\n","    # and add this ratio to the ohlcv.csv as the \"behav\" column\n","    behav_df = trade.groupby('time')['price_up_down'].value_counts().unstack()\n","    behav_df['sum'] = (behav_df.sum(axis=1)).fillna(-1)\n","    ohlcv['behav'] = behav_df[1] / behav_df['sum']\n","    \n","    ohlcv = ohlcv.loc[20:]                                                              # Drop first 20 minute data for each day \n","    ohlcv = ohlcv[['ud','ma','volume','behav']]                                         # Leave only the columns that will be used in the modeling\n","    ohlcv.loc[:,'volume'] = ohlcv['volume'].apply(lambda x: np.log(x))                  # Apply log to the volume data, considering the large range of the data\n","    ohlcv = ohlcv.astype('float32')\n","    \n","    ohlcv.to_csv(os.path.join(preprocessed_data_path,ohlcv_date+'.csv'), index=False, header=False)"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 30/30 [00:00<00:00, 556.32it/s]\n"]}],"source":["# Merge the daily preprocessed csv files into a single csv file\n","\n","preprocessed_data_files = sorted(os.listdir(preprocessed_data_path))\n","preprocessed_column_list = ['ud','ma','volume','behav']\n","\n","data = pd.read_csv(os.path.join(preprocessed_data_path,preprocessed_data_files[0]),names=preprocessed_column_list)\n","for file in tqdm(preprocessed_data_files[1:]):\n","    df = pd.read_csv(os.path.join(preprocessed_data_path,file),names=preprocessed_column_list)\n","    data = pd.concat([data,df],axis=0)\n","\n","data = data.reset_index().drop('index',axis=1)"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[],"source":["# Replace the values of 1% anomaly data to the 1% boundary values\n","\n","data['ud'] = data['ud'].apply(lambda x: max(min(x,150),-150))\n","data['ma'] = data['ma'].apply(lambda x: max(min(x,300),-300))\n","data['volume'] = data['volume'].apply(lambda x: max(min(x,5.5),1.2))"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["data.to_csv('input_data_2021-12.csv',index=False,header=False)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOmmroD2IPxnGn0yXI4RotN","collapsed_sections":[],"name":"csv.ipynb","provenance":[]},"kernelspec":{"display_name":"jjh1","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15 (main, Nov 24 2022, 08:29:02) \n[Clang 14.0.6 ]"},"vscode":{"interpreter":{"hash":"15f4aacd9556265f1615cc73c631931044efcc45c198588ea5b6a55eacfa69f4"}}},"nbformat":4,"nbformat_minor":0}
